# ğŸ§  Agentic Second Brain (ASB)

A fully-local, **autonomous personal intelligence system** built in Python.  
Your ASB learns from your notes, projects, reflections, and research â€” thinking, summarizing, and improving just like a human brain.

> âš™ï¸ Powered by **Ollama**, **LangChain**, **Chroma**, and **Typer CLI**

---

## ğŸ“š Table of Contents
1. [Overview](#overview)
2. [Architecture](#architecture)
3. [Setup](#setup)
4. [Environment Variables](#environment-variables)
5. [CLI Usage](#cli-usage)
6. [Phases Implemented](#phases-implemented)
7. [Intelligence Stack](#intelligence-stack)
8. [Autonomous Research (Phase 8)](#autonomous-research-phase8)
9. [Example Flow](#example-flow)
10. [Future Roadmap](#future-roadmap)
11. [Author & License](#author--license)

---

## ğŸ§© Overview

ASB is your **Agentic Second Brain** â€” an evolving system that:
- ğŸ§  Stores and embeds your notes for semantic recall  
- ğŸª Reflects on what youâ€™ve learned  
- ğŸ”„ Self-evaluates and improves its reasoning  
- ğŸŒ Performs autonomous research  
- ğŸ§© Compresses and organizes knowledge over time  

Everything runs **locally via Ollama**, ensuring privacy and full offline operation.

---

## ğŸ—ï¸ Architecture

asb/
â”œâ”€â”€ asb/
â”‚   â”œâ”€â”€ brain/
â”‚   â”‚   â”œâ”€â”€ agent.py              # Orchestrates cognition + reasoning
â”‚   â”‚   â”œâ”€â”€ cognition.py          # Ollama-based thinking module
â”‚   â”‚   â”œâ”€â”€ memory.py             # Vector memory via Chroma + embeddings
â”‚   â”‚   â”œâ”€â”€ reflection.py         # Reflection engine (summary + follow-up)
â”‚   â”‚   â”œâ”€â”€ insight_db.py         # SQLite database for insights
â”‚   â”‚   â”œâ”€â”€ scheduler.py          # Time-based jobs with timeout
â”‚   â”‚   â”œâ”€â”€ logger.py             # Persistent daily logs
â”‚   â”‚   â”œâ”€â”€ self_evaluator.py     # Reflection scoring & feedback
â”‚   â”‚   â”œâ”€â”€ memory_compressor.py  # Long-term memory consolidation
â”‚   â”‚   â”œâ”€â”€ ingestion.py          # Context ingestion from Git/Notion/files
â”‚   â”‚   â”œâ”€â”€ research_agent.py     # Autonomous research & summarization
â”‚   â”‚   â””â”€â”€ sources/              # Modular adapters (Git, Notion, Local)
â”‚   â”œâ”€â”€ main.py                   # Typer CLI entrypoint
â”‚   â””â”€â”€ init.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ notes/
â”‚   â”œâ”€â”€ reflections/
â”‚   â”œâ”€â”€ compressed/
â”‚   â”œâ”€â”€ questions/
â”‚   â”œâ”€â”€ metrics/
â”‚   â”œâ”€â”€ logs/
â”‚   â””â”€â”€ vector_store/
â””â”€â”€ pyproject.toml

---

## âš™ï¸ Setup

### 1ï¸âƒ£ Install dependencies
```bash
uv sync

2ï¸âƒ£ Install & run Ollama

# macOS / Linux
brew install ollama
ollama pull llama3.1:8b
ollama serve

3ï¸âƒ£ Environment Variables

Create a .env file in your root folder:

DATA_DIR=./data/notes
VECTOR_DIR=./data/vector_store
OLLAMA_MODEL=llama3.1:8b
OLLAMA_EMBED_MODEL=nomic-embed-text
SERPER_API_KEY=your_serper_api_key_here   # optional web search
NOTION_API_KEY=your_notion_api_key_here   # optional


â¸»

ğŸ§  CLI Usage

Command	Description
uv run asb ingest	Ingest notes into semantic memory
uv run asb ask "What did I learn about RabbitMQ persistence?"	Query your brain
uv run asb reflect	Generate reflection & follow-up questions
uv run asb schedule -t 1	Run reflection scheduler for 1 hour
uv run asb ingest-all	Ingest from Git, Notion, and markdown sources
uv run asb insights retry	Query stored insights by topic
uv run asb compress -d 14	Compress reflections older than 14 days
uv run asb evaluate -d 7	Score last 7 reflections for quality
uv run asb metrics	Show average reflection scores
uv run asb focus	Suggest next learning directions
uv run asb research -m 3	Auto-research 3 open questions via Ollama
uv run asb logs -d 1	View last day of activity logs


â¸»

ğŸ”¢ Phases Implemented

Phase 1 â€” Core MVP
	â€¢	Typer CLI + Rich output
	â€¢	ChromaDB vector memory
	â€¢	LLM cognition via Ollama (local) or OpenAI fallback

Phase 2 â€” Living Memory
	â€¢	Auto-ingestion and reflection system
	â€¢	Knowledge graph creation
	â€¢	Timed jobs via APScheduler

Phase 3 â€” Self-Reflective Intelligence
	â€¢	Writes reflection files (reflection_YYYY-MM-DD.md)
	â€¢	Generates follow-up questions automatically

Phase 4 â€” System Awareness
	â€¢	Persistent action logs (data/logs/)
	â€¢	ASB reflects on its own performance

Phase 5 â€” Contextual Autonomy
	â€¢	Modular source adapters: Git, Notion, Local Files
	â€¢	Unified ingestion: uv run asb ingest-all

Phase 6 â€” Memory Compression
	â€¢	Summarizes older reflections into key insights
	â€¢	Stores compressed results in DB + /data/compressed

Phase 7 â€” Cognitive Feedback
	â€¢	Scores reflections (clarity, novelty, redundancy)
	â€¢	Tracks metrics in /data/metrics/self_scores.csv
	â€¢	Suggests new focus areas via uv run asb focus

Phase 8 â€” Autonomous Research (Ollama-powered)
	â€¢	Reads open questions from /data/questions/open_questions.md
	â€¢	Uses Ollama for reasoning and summarization
	â€¢	Optional web-search snippets via SERPER_API_KEY
	â€¢	Stores findings in both Insight DB and vector memory
	â€¢	Triggers automatic post-research reflection

â¸»

ğŸ§¬ Autonomous Research (Phase 8)

ğŸ”§ Configuration

.env

OLLAMA_MODEL=llama3.1:8b
SERPER_API_KEY=optional

ğŸ” Run Research

uv run asb research -m 2

Output:

ğŸ” Researching: How does CPU affinity impact RPC performance?
ğŸ§  New insight added to long-term memory.
ğŸ” Researching: What retry strategies improve persistence?
ğŸ§  New insight added to long-term memory.
âœ… Research cycle complete â€” 2 questions processed.
ğŸª Initiating post-research reflection...
âœ¨ Reflection after research completed.

ğŸ’¡ What Happens
	1.	Pulls open questions â†’ performs web search (optional).
	2.	Summarizes findings locally using Ollama LLM.
	3.	Writes them into:
	â€¢	insight_db (structured memory)
	â€¢	Chroma vector store (semantic recall)
	4.	Triggers reflection to integrate new learnings.

â¸»

ğŸ§  Intelligence Stack

Layer	Implementation
Reasoning	Ollama LLM (llama3.1:8b, phi3, etc.)
Embeddings	Local HuggingFace or Ollama embeddings
Memory	ChromaDB vector store
Long-term storage	SQLite (insight_db.py)
Reflection	ReflectionEngine (summarization + questioning)
Evaluation	SelfEvaluator (clarity, novelty, redundancy)
Compression	MemoryCompressor (long-term summarization)
Research	ResearchAgent (Ollama-based summarization + web search)


â¸»

ğŸ§© Example Flow

# 1. Ingest notes
uv run asb ingest

# 2. Reflect on learnings
uv run asb reflect

# 3. Compress old reflections
uv run asb compress -d 14

# 4. Self-evaluate reflections
uv run asb evaluate -d 7
uv run asb metrics

# 5. Auto-research open questions
uv run asb research -m 3

# 6. Review new insights
uv run asb insights research


â¸»

ğŸš€ Future Roadmap

Phase 9 â€” Insight Dashboard
	â€¢	Streamlit-based visualization
	â€¢	Reflection timelines, scores, and knowledge graph

Phase 10 â€” Emotional Context Modeling
	â€¢	Track tone, stress, and motivation in reflections

Phase 11 â€” Continuous Learning
	â€¢	Real-time integration with GitHub activity, papers, and notes

â¸»

ğŸ§‘â€ğŸ’» Author

Chitrank Dixit
Building an evolving, privacy-first AI system that learns alongside its creator.

â¸»

ğŸ§¾ License

MIT License Â© 2025 Chitrank Dixit

â€œYour second brain should think with you, not for you.â€

---

Would you like me to add optional **badges** (Python | Ollama | LangChain | Made with uv) and a **project banner header** so the README looks fully production-ready for GitHub?